{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3247f86",
   "metadata": {},
   "source": [
    "# Travel Comment Sentiment Classification\n",
    "### YouTube Travel Buzz NLP Pipeline ‚Äì Module 2\n",
    "\n",
    "Multi-class sentiment classification model (Negative / Neutral / Positive)\n",
    "applied to travel-related YouTube comments.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c55f585",
   "metadata": {},
   "source": [
    "### 0. Execution Note\n",
    "\n",
    "This notebook contains **actual training, evaluation, and inference outputs**\n",
    "generated during the project period.\n",
    "\n",
    "Due to the use of private local paths and time-bound compute environments:\n",
    "- File paths were anonymized\n",
    "- Authentication-related steps were removed\n",
    "- The notebook is **not intended for re-execution**\n",
    "\n",
    "All model logic, metrics, and outputs remain unchanged.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "430aa4d4",
   "metadata": {},
   "source": [
    "### 1. Environment Setup\n",
    "\n",
    "Required libraries for sentiment model training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a588af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "836ce326",
   "metadata": {},
   "source": [
    "### 2. Training Data Loading\n",
    "\n",
    "- Input: CSV file containing `comment` and `label`\n",
    "- Labels: 0 (Negative), 1 (Neutral), 2 (Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a316eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/travel_comment_sentiment_train.csv\"  # anonymized path\n",
    "\n",
    "# NOTE:\n",
    "# Original data was loaded from a local private path.\n",
    "# Path anonymized for public GitHub release.\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ef1ff03",
   "metadata": {},
   "source": [
    "### 3. Dataset Construction\n",
    "\n",
    "Convert pandas DataFrame to Hugging Face Dataset and split into train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bcae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a63a588",
   "metadata": {},
   "source": [
    "### 4. Model & Tokenizer Initialization\n",
    "\n",
    "Base model: `monologg/koelectra-base-discriminator`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea08385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"monologg/koelectra-base-discriminator\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=3\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3494e3cc",
   "metadata": {},
   "source": [
    "### 5. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"comment\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"sentiment\", \"labels\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c12c5fd",
   "metadata": {},
   "source": [
    "### 6. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cc2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06b76ab4",
   "metadata": {},
   "source": [
    "### 7. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c22040",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    seed=42,\n",
    "    logging_dir=\"./sentiment_logs\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edb33c62",
   "metadata": {},
   "source": [
    "### 8. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8596c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8cc2e78",
   "metadata": {},
   "source": [
    "### 9. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b226e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3840/3840 [00:00<00:00, 17080.05 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 960/960 [00:00<00:00, 18954.72 examples/s]\n",
      "C:\\Users\\rhksd\\AppData\\Local\\Temp\\ipykernel_15204\\2031024620.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 2:17:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.174383</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.939536</td>\n",
       "      <td>0.940625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.955907</td>\n",
       "      <td>0.956250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.119921</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.962232</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.127640</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.962210</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.126816</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.963291</td>\n",
       "      <td>0.963542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: C:\\Users\\rhksd\\Desktop\\Data\\Ìï≠Í≥µ\\travel_comment_classifier_sentiment_3class\n"
     ]
    }
   ],
   "source": [
    "# Model was saved locally during the project period.\n",
    "# Path omitted for public release.\n",
    "\n",
    "save_path = \"./models/travel_comment_classifier_sentiment_3class\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {save_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5421253",
   "metadata": {},
   "source": [
    "### 10. Sentiment Comment Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"model/travel_comment_sentiment_classifier\")  # placeholder\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "def predict_comment(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "    return pred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d5e942",
   "metadata": {},
   "source": [
    "### 11. Batch Sentiment Inference on YouTube Comments\n",
    "\n",
    "Apply the classifier to real YouTube comments and analyze confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"data/youtube_travel_comments.csv\")  # anonymized\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df[\"pred_label\"] = df[\"comment\"].apply(predict_comment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88f81871",
   "metadata": {},
   "source": [
    "### 12. Sentiment Distribution Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ce4346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Í∞êÏ†ï Î∂ÑÌè¨ ÏöîÏïΩ:\n",
      "  Î∂ÄÏ†ï  : 61Í∞ú (10.50%)\n",
      "  Ï§ëÎ¶Ω  : 56Í∞ú (9.64%)\n",
      "  Í∏çÏ†ï  : 464Í∞ú (79.86%)\n",
      "\n",
      "‚úÖ Ï¥ù ÎåìÍ∏Ä Ïàò: 581Í∞ú\n",
      "üìÅ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: C:\\Users\\rhksd\\Desktop\\Data\\Ìï≠Í≥µ\\drive-download-20250604T053503Z-1-001\\phuquoc_comment_data_2023-01_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: \"Î∂ÄÏ†ï\", 1: \"Ï§ëÎ¶Ω\", 2: \"Í∏çÏ†ï\"}\n",
    "\n",
    "summary = (\n",
    "    df[\"pred_label\"]\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .rename(index=label_map)\n",
    ")\n",
    "\n",
    "total = len(df)\n",
    "\n",
    "print(\"\\nüîé Í∞êÏ†ï Î∂ÑÌè¨ ÏöîÏïΩ:\")\n",
    "for label, count in summary.items():\n",
    "    pct = count / total * 100\n",
    "    print(f\"  {label: <4}: {count}Í∞ú ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Ï¥ù ÎåìÍ∏Ä Ïàò: {total}Í∞ú\")\n",
    "print(f\"üìÅ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: {output_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f45cb594",
   "metadata": {},
   "source": [
    "### 13. Interpretation of Inference Results\n",
    "\n",
    "The inference results show that the sentiment classifier produces a stable and interpretable distribution across negative, neutral, and positive classes on real-world travel-related comments.\n",
    "\n",
    "Key observations from the output include:\n",
    "\n",
    "- Positive sentiment accounts for the majority of comments, which is consistent with the aspirational and experiential nature of travel content.\n",
    "- Negative sentiment appears in smaller proportions, suggesting that dissatisfaction is present but not dominant.\n",
    "- Neutral sentiment represents a meaningful share of comments, reflecting information-seeking behavior such as questions, factual statements, and planning-related inquiries.\n",
    "\n",
    "This confirms that the three-class sentiment formulation avoids forcing ambiguous comments into polar categories and better captures realistic user discourse.\n",
    "\n",
    "The resulting sentiment labels are used as aggregated signals in downstream analysis rather than as standalone judgments on individual comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
